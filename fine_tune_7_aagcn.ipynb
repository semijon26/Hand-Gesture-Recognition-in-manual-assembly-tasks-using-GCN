{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:37:21.708275600Z",
     "start_time": "2024-01-10T10:37:17.161290800Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from model import aagcn, loss, SAM\n",
    "from utils import adj_mat, training_supervision\n",
    "from data.handpose_dataset import HandPoseDatasetNumpy, df_to_numpy\n",
    "from data.get_data_from_csv import get_train_data, get_val_data\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "from config_fine_tuning_occluded_hand_detection import CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e18a904b2db6ab6a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": "Model(\n  (data_bn): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (l1): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (down): Sequential(\n        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l2): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l3): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l4): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l5): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(128, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(128, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=128, out_features=64, bias=True)\n      (fc2c): Linear(in_features=64, out_features=128, bias=True)\n      (down): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(9, 1), stride=(2, 1), padding=(4, 0))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n    (residual): unit_tcn(\n      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 1))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (l6): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(128, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(128, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=128, out_features=64, bias=True)\n      (fc2c): Linear(in_features=64, out_features=128, bias=True)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l7): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(128, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(128, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=128, out_features=64, bias=True)\n      (fc2c): Linear(in_features=64, out_features=128, bias=True)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(9, 1), stride=(2, 1), padding=(4, 0))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n    (residual): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 1))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (fc): Linear(in_features=128, out_features=6, bias=True)\n  (drop_out): Dropout(p=0.5, inplace=False)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'trained_models/7_AAGCN_Focal_seqlen32_release_SAM_joints1_joints2_oridist/f10.8142688679245284_valloss310.2437744140625_epoch13.pth'\n",
    "\n",
    "graph = aagcn.Graph(adj_mat.num_node, adj_mat.self_link, adj_mat.inward, adj_mat.outward, adj_mat.neighbor)\n",
    "\n",
    "model = aagcn.Model(num_class=CFG.num_classes, num_point=21, num_person=1, graph=graph, drop_out=0.5,\n",
    "                    in_channels=CFG.num_feats)\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:37:23.494463600Z",
     "start_time": "2024-01-10T10:37:23.034303700Z"
    }
   },
   "id": "2169ad9f860d1525"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modify model -> 3 classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11b0dce12eb5a46"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[ 7.0185e-02,  2.4771e-01,  3.9396e-01, -8.9168e-01, -3.9525e-01,\n         -2.9742e-01,  9.7565e-01, -7.8637e-01,  2.3552e-01, -1.1848e-02,\n         -1.7289e-01, -4.1561e-01,  1.3128e+00, -1.3293e-01, -7.3596e-01,\n          6.0861e-01, -3.7974e-01, -3.4785e-01,  1.5284e-01,  1.9753e+00,\n         -9.3133e-02, -1.1806e+00, -1.0907e+00, -6.5592e-01,  5.7587e-01,\n          7.9708e-01, -1.7051e+00,  9.7193e-01, -1.1896e+00,  9.7583e-01,\n         -1.7357e-01,  3.0579e-02,  6.1332e-01,  2.7959e-01,  3.5409e-01,\n          4.4103e-01,  3.3847e-02,  8.6670e-01, -1.2781e-01, -8.7633e-02,\n         -7.7093e-01,  7.0282e-01,  7.6958e-01,  5.4175e-03,  3.7363e-01,\n          6.8676e-01,  3.3440e-01,  8.1575e-02,  4.9630e-01,  8.7347e-01,\n          2.6750e-01,  4.1464e-01, -7.0487e-01, -4.8187e-01, -9.1393e-02,\n         -1.4350e+00,  5.2016e-01, -3.4967e-01,  1.1869e+00,  5.2113e-01,\n         -6.7805e-01, -2.2267e-01, -5.8908e-01, -4.9559e-01, -1.5941e-02,\n          2.2645e-01, -1.3190e+00,  7.6871e-01,  1.4992e+00, -6.9731e-01,\n          1.2855e+00,  5.5581e-01,  6.4278e-01,  9.6309e-01,  5.5420e-01,\n          6.6428e-01,  4.5456e-01,  9.0667e-01, -3.2051e-02,  1.4640e-02,\n         -7.6925e-01, -3.2066e-01, -8.9525e-01, -1.3208e+00, -1.7283e-01,\n          7.8630e-01, -1.4176e-01,  5.1049e-01,  1.0757e+00, -4.2189e-01,\n          5.4702e-01, -3.5455e-01,  4.5016e-01, -4.5863e-01, -9.5986e-01,\n         -5.2769e-01,  1.1153e-01,  2.5397e-01,  9.2881e-01, -1.1328e+00,\n          2.0008e-01,  7.1503e-01, -2.8632e-01,  1.4454e+00,  6.0355e-01,\n          2.0034e-01,  5.3563e-01,  3.4732e-01, -1.0019e+00, -1.8206e+00,\n         -5.9471e-01, -9.2062e-01,  1.7883e+00, -4.4849e-01, -1.3802e-01,\n         -3.3944e-01,  1.0095e+00, -1.8147e+00, -3.8985e-01, -1.5972e-01,\n         -5.0645e-01, -1.1056e+00,  1.4785e-01,  3.5485e-01, -1.0774e-01,\n         -2.0089e-01, -9.7134e-01,  7.2260e-02],\n        [-4.4760e-02, -2.2257e+00,  8.8663e-01, -9.3048e-01, -2.9087e-01,\n          1.1549e+00,  6.7752e-02, -6.6303e-01,  9.5800e-01, -6.5921e-01,\n          1.2487e+00, -7.7833e-01,  4.9792e-01, -5.2007e-01, -2.0108e-01,\n         -2.8965e-01, -1.1228e+00,  5.9683e-01,  8.9700e-01,  3.3571e-01,\n         -1.3429e+00,  1.9841e+00, -7.1926e-01,  1.2854e+00,  5.9604e-01,\n         -9.0751e-02, -3.6688e-01,  4.4814e-01, -9.1532e-02, -1.0407e+00,\n          2.3967e+00, -6.2710e-01,  7.2394e-01, -6.6653e-01,  1.4288e-01,\n          5.0147e-03, -3.8133e-01,  7.1689e-01, -1.6173e+00,  5.9976e-01,\n         -2.1808e-01,  7.8925e-01,  4.2869e-01,  4.1089e-01,  1.1900e-01,\n         -6.5213e-01,  8.7214e-01,  2.1814e-01, -1.9982e-01,  8.8308e-01,\n         -7.5997e-02, -1.3932e+00,  5.8943e-01, -6.4557e-01, -1.8558e+00,\n         -1.3522e+00,  8.5935e-01,  5.2419e-01, -1.3905e+00, -7.2200e-01,\n          1.6015e-01,  2.0856e-01,  5.2873e-01,  1.2958e-01,  5.9621e-01,\n          6.9117e-01, -5.0355e-02, -6.3034e-01, -5.6490e-01, -3.9930e-01,\n          1.0344e+00,  1.0255e+00,  3.8476e-01, -4.6959e-01, -4.5989e-01,\n         -6.5163e-02, -2.3727e-01, -1.3712e+00, -5.8276e-01,  1.1037e+00,\n         -9.4094e-01,  8.1093e-01,  1.2895e+00,  3.9845e-01,  7.2683e-01,\n          7.8952e-01, -1.3018e-02, -1.8772e+00, -3.5130e-01,  6.0387e-01,\n         -1.2395e-01, -4.5122e-01, -2.2254e-01, -1.1932e+00, -4.8818e-01,\n          5.1222e-01,  6.4976e-01, -1.2641e+00,  6.6943e-01, -1.1995e-01,\n          9.4710e-01,  3.9297e-01, -9.4779e-01, -5.4971e-01, -3.0243e-01,\n         -5.7947e-01,  1.0304e+00, -1.5229e+00,  9.8005e-01, -2.3685e-01,\n         -5.1431e-01, -1.7690e-02, -7.8752e-02, -7.7933e-02,  1.8717e-01,\n         -5.9099e-01, -1.2399e-01,  8.8434e-01, -7.2629e-01,  1.4173e+00,\n         -5.7551e-01,  5.3503e-01,  7.1155e-01, -1.2415e+00,  1.5956e+00,\n         -6.2099e-03,  2.0891e+00,  9.2860e-01],\n        [ 1.9307e-01,  8.3299e-01,  4.3204e-01,  6.0331e-01, -5.6316e-01,\n         -5.2241e-01,  1.4919e+00,  1.0015e+00,  8.0247e-01,  9.2523e-01,\n         -9.1499e-01,  1.7214e-01,  5.6548e-01,  7.1151e-01, -1.7697e+00,\n         -7.6495e-01,  2.2333e+00, -2.2579e-01,  6.5255e-01, -8.3297e-01,\n         -3.6158e-01,  9.6427e-02,  1.2792e+00, -3.9217e-01, -9.5114e-01,\n          1.5636e-02, -1.2546e-01,  1.2910e+00,  5.7945e-01,  2.4091e-03,\n         -4.1714e-02, -4.5698e-01,  6.0428e-01,  4.8132e-01, -1.2074e+00,\n         -1.1271e+00, -1.6236e+00,  8.0950e-01,  3.9580e-01, -9.2176e-01,\n          8.3443e-01, -4.3025e-01, -1.6108e-01, -1.6399e+00, -4.9754e-01,\n         -1.3696e+00, -7.2498e-01, -2.7252e-02, -1.0249e+00,  2.0225e-01,\n         -3.7008e-01,  1.0082e+00, -2.8853e-02, -5.4651e-01, -3.7900e-01,\n          8.5890e-01,  2.6202e-01, -3.7573e-01,  3.1498e-02,  2.9303e-01,\n         -9.7008e-01,  2.6558e-01,  9.9385e-01,  7.6429e-01,  2.7184e-01,\n         -7.1267e-01,  3.7605e-01, -9.0994e-01,  4.1545e-01,  5.3979e-01,\n         -6.0125e-01,  6.9691e-01,  1.4216e+00,  6.2713e-02, -3.8726e-01,\n         -5.8998e-01,  2.0396e-03, -3.1439e-02,  6.6860e-01, -1.6697e-01,\n          7.3050e-01, -2.7715e-01,  3.2487e-01, -5.8709e-01, -3.1739e-01,\n         -5.7807e-01, -1.1111e+00, -3.8818e-01, -1.2206e+00, -3.8524e-01,\n          1.1141e+00, -7.2853e-01,  1.0321e+00,  4.0043e-01, -9.0378e-02,\n          6.7306e-01, -1.3209e+00, -6.8439e-02, -5.5079e-01, -2.0426e-01,\n          1.0740e+00, -1.0874e+00,  2.1173e-02, -5.7534e-01,  4.3016e-01,\n          8.8942e-01, -5.7254e-01,  1.8362e-01,  2.0096e-01,  7.3785e-01,\n         -3.0192e-01,  2.2550e+00, -2.7157e-01, -8.9833e-02, -5.6714e-01,\n         -1.9764e-01,  6.1318e-01, -8.5879e-01, -8.4458e-01, -1.5720e-01,\n         -5.5096e-01,  1.0204e+00, -1.1833e-01, -8.0547e-01,  6.8124e-01,\n          1.4552e+00, -5.1274e-01, -1.0969e+00]], device='cuda:0',\n       requires_grad=True)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_fine_tuning = len(CFG.classes_fine_tuning)\n",
    "\n",
    "# change last layer\n",
    "model.fc = nn.Linear(128, num_classes_fine_tuning).to(device)\n",
    "\n",
    "# init the new layer\n",
    "nn.init.normal_(model.fc.weight, 0, math.sqrt(2. / num_classes_fine_tuning))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:37:25.396303700Z",
     "start_time": "2024-01-10T10:37:25.335289Z"
    }
   },
   "id": "dc1758e49dcac320"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9eac5679f84793c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       WRIST  THUMB_CMC  THUMB_MCP   THUMB_IP  THUMB_TIP INDEX_FINGER_MCP  \\\n0  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n1  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n2  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n3  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n4  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n\n  INDEX_FINGER_PIP INDEX_FINGER_DIP INDEX_FINGER_TIP MIDDLE_FINGER_MCP  ...  \\\n0        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n1        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n2        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n3        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n4        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n\n  MIDDLE_FINGER_TIP RING_FINGER_MCP RING_FINGER_PIP RING_FINGER_DIP  \\\n0         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n1         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n2         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n3         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n4         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n\n  RING_FINGER_TIP  PINKY_MCP  PINKY_PIP  PINKY_DIP  PINKY_TIP     LABEL  \n0       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n1       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n2       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n3       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n4       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WRIST</th>\n      <th>THUMB_CMC</th>\n      <th>THUMB_MCP</th>\n      <th>THUMB_IP</th>\n      <th>THUMB_TIP</th>\n      <th>INDEX_FINGER_MCP</th>\n      <th>INDEX_FINGER_PIP</th>\n      <th>INDEX_FINGER_DIP</th>\n      <th>INDEX_FINGER_TIP</th>\n      <th>MIDDLE_FINGER_MCP</th>\n      <th>...</th>\n      <th>MIDDLE_FINGER_TIP</th>\n      <th>RING_FINGER_MCP</th>\n      <th>RING_FINGER_PIP</th>\n      <th>RING_FINGER_DIP</th>\n      <th>RING_FINGER_TIP</th>\n      <th>PINKY_MCP</th>\n      <th>PINKY_PIP</th>\n      <th>PINKY_DIP</th>\n      <th>PINKY_TIP</th>\n      <th>LABEL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = get_train_data()  # Todo: replace with our own data\n",
    "df_train = df_train.replace(\"Postion\", \"Position\")\n",
    "df_val = get_val_data()  # Todo: replace with our own data\n",
    "\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T10:37:29.014672600Z",
     "start_time": "2024-01-10T10:37:27.104741200Z"
    }
   },
   "id": "49df6f288d86c4ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finetuning first try: remove all other classes except our 3 from the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e22c6215d8a5efd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27184 entries, 0 to 2021\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   WRIST              27184 non-null  object\n",
      " 1   THUMB_CMC          27184 non-null  object\n",
      " 2   THUMB_MCP          27184 non-null  object\n",
      " 3   THUMB_IP           27184 non-null  object\n",
      " 4   THUMB_TIP          27184 non-null  object\n",
      " 5   INDEX_FINGER_MCP   27184 non-null  object\n",
      " 6   INDEX_FINGER_PIP   27184 non-null  object\n",
      " 7   INDEX_FINGER_DIP   27184 non-null  object\n",
      " 8   INDEX_FINGER_TIP   27184 non-null  object\n",
      " 9   MIDDLE_FINGER_MCP  27184 non-null  object\n",
      " 10  MIDDLE_FINGER_PIP  27184 non-null  object\n",
      " 11  MIDDLE_FINGER_DIP  27184 non-null  object\n",
      " 12  MIDDLE_FINGER_TIP  27184 non-null  object\n",
      " 13  RING_FINGER_MCP    27184 non-null  object\n",
      " 14  RING_FINGER_PIP    27184 non-null  object\n",
      " 15  RING_FINGER_DIP    27184 non-null  object\n",
      " 16  RING_FINGER_TIP    27184 non-null  object\n",
      " 17  PINKY_MCP          27184 non-null  object\n",
      " 18  PINKY_PIP          27184 non-null  object\n",
      " 19  PINKY_DIP          27184 non-null  object\n",
      " 20  PINKY_TIP          27184 non-null  object\n",
      " 21  LABEL              27184 non-null  object\n",
      "dtypes: object(22)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train[df_train[\"LABEL\"].isin(CFG.classes_fine_tuning)]\n",
    "df_val = df_val[df_val[\"LABEL\"].isin(CFG.classes_fine_tuning)]\n",
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:02.271545Z",
     "start_time": "2024-01-10T00:36:02.115329100Z"
    }
   },
   "id": "8dc0787fc2d358cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare train and validation data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29aab5179473bf86"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TRAIN DATA DISTRIBUTION\n",
      "LABEL\n",
      "Grasp       19445\n",
      "Negative     5011\n",
      "Release      2728\n",
      "Name: count, dtype: int64\n",
      "[INFO] VALIDATION DATA DISTRIBUTION\n",
      "LABEL\n",
      "Grasp       3679\n",
      "Negative    1117\n",
      "Release      380\n",
      "Name: count, dtype: int64\n",
      "[INFO] TRAINING ON 27184 DATAPOINTS\n",
      "[INFO] VALIDATION ON 5176 DATAPOINTS\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] TRAIN DATA DISTRIBUTION\")\n",
    "print(df_train[\"LABEL\"].value_counts())\n",
    "print(\"[INFO] VALIDATION DATA DISTRIBUTION\")\n",
    "print(df_val[\"LABEL\"].value_counts())\n",
    "\n",
    "train_numpy = df_to_numpy(df_train)\n",
    "val_numpy = df_to_numpy(df_val)\n",
    "\n",
    "train_set = HandPoseDatasetNumpy(train_numpy)\n",
    "val_set = HandPoseDatasetNumpy(val_numpy)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=CFG.batch_size, drop_last=True, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=CFG.batch_size, drop_last=True, pin_memory=True)\n",
    "\n",
    "print(f\"[INFO] TRAINING ON {len(train_set)} DATAPOINTS\")\n",
    "print(f\"[INFO] VALIDATION ON {len(val_set)} DATAPOINTS\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:11.938905400Z",
     "start_time": "2024-01-10T00:36:02.178469Z"
    }
   },
   "id": "b415ca84109554c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fine tuning config and preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9db523fbb4200c5d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "optimizer_base = torch.optim.Adam\n",
    "optimizer = SAM.SAM(model.parameters(), optimizer_base, lr=CFG.lr, rho=0.5, adaptive=True)\n",
    "criterion = loss.FocalLoss()\n",
    "\n",
    "writer = SummaryWriter(f'fine_tuned_models_occluded_hand_detection/runs/{CFG.experiment_name}')\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=CFG.min_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:11.957911900Z",
     "start_time": "2024-01-10T00:36:11.941906200Z"
    }
   },
   "id": "ad310ad7e2983f47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_func(model, data_loader, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    iters = len(data_loader)\n",
    "    global_step = epoch * len(data_loader)\n",
    "    preds = []\n",
    "    groundtruth = []\n",
    "    t0 = time.time()\n",
    "    loss_total = 0\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        labels = labels.cuda().long()\n",
    "        inputs = inputs.cuda().float()\n",
    "\n",
    "        last_label = labels[:, -1, :]\n",
    "        last_label = torch.argmax(last_label, 1)\n",
    "\n",
    "        model.zero_grad()\n",
    "        last_out = model(inputs)\n",
    "\n",
    "        # first forward-backward pass\n",
    "        loss = criterion(last_out, last_label)\n",
    "        loss.backward()\n",
    "\n",
    "        if CFG.sam:\n",
    "            optimizer.first_step(zero_grad=True)  #\n",
    "\n",
    "            # second forward-backward pass\n",
    "            criterion(model(inputs), last_label).backward()  #\n",
    "            optimizer.second_step(zero_grad=True)  #\n",
    "        else:\n",
    "            optimizer.step()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        preds.append(last_out.cpu().detach().numpy())\n",
    "        groundtruth.append(last_label.cpu().detach().numpy())\n",
    "\n",
    "        loss_total += loss\n",
    "        global_step += 1\n",
    "        writer.add_scalar('Loss/Train', loss, global_step)\n",
    "        writer.add_scalar('LR', current_lr, global_step)\n",
    "\n",
    "        if i % CFG.print_freq == 1 or i == iters - 1:\n",
    "            t1 = time.time()\n",
    "            print(\n",
    "                f\"[TRAIN] Epoch: {epoch}/{CFG.epochs} | Iteration: {i}/{iters} | Loss: {loss_total / i} | LR: {current_lr} | ETA: {((t1 - t0) / i * iters) - (t1 - t0)}s\")\n",
    "\n",
    "    return loss_total, np.argmax(preds, axis=2).flatten(), np.array(groundtruth).flatten()\n",
    "\n",
    "\n",
    "def eval_func(model, criterion, data_loader, epoch):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    groundtruth = []\n",
    "    t0 = time.time()\n",
    "    loss_total = 0\n",
    "    global_step = len(train_loader) * epoch\n",
    "    iters = len(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            labels = labels.cuda().long()\n",
    "            inputs = inputs.cuda().float()\n",
    "\n",
    "            last_label = labels[:, -1, :]\n",
    "            last_label = torch.argmax(last_label, 1)\n",
    "\n",
    "            last_out = model(inputs)\n",
    "            loss = criterion(last_out, last_label)\n",
    "\n",
    "            preds.append(last_out.cpu().detach().numpy())\n",
    "            groundtruth.append(last_label.cpu().detach().numpy())\n",
    "            loss_total += loss\n",
    "\n",
    "            if i % CFG.print_freq == 1 or i == iters - 1:\n",
    "                t1 = time.time()\n",
    "                print(\n",
    "                    f\"[EVAL] Epoch: {epoch}/{CFG.epochs} | Iteration: {i}/{iters} | Val-Loss: {loss_total / i} | ETA: {((t1 - t0) / i * iters) - (t1 - t0)}s\")\n",
    "\n",
    "    writer.add_scalar('Loss/Validation', loss_total / i, global_step)\n",
    "    return loss_total, np.argmax(preds, axis=2).flatten(), np.array(groundtruth).flatten()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f58e55abe0c3428f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Early stopping to stop training automatically when model doesn't improve anymore"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccfc21c34681e185"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, delta=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:11.979018100Z",
     "start_time": "2024-01-10T00:36:11.958912200Z"
    }
   },
   "id": "b0e3fc32c91296cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start Fine tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe8f85ca1658b36b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m global_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader) \u001B[38;5;241m*\u001B[39m epoch\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#TRAIN\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m train_loss, preds_train, gt_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m train_grad_flow_plot \u001B[38;5;241m=\u001B[39m training_supervision\u001B[38;5;241m.\u001B[39mget_plot_grad_flow(model)\n\u001B[0;32m     10\u001B[0m f1_train \u001B[38;5;241m=\u001B[39m f1_score(gt_train, preds_train, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmicro\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\train.py:76\u001B[0m, in \u001B[0;36mtrain_func\u001B[1;34m(model, data_loader, criterion, optimizer, scheduler, epoch)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# first forward-backward pass\u001B[39;00m\n\u001B[0;32m     75\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(last_out, last_label)\n\u001B[1;32m---> 76\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m CFG\u001B[38;5;241m.\u001B[39msam:\n\u001B[0;32m     79\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mfirst_step(zero_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m#\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\venv\\lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:244\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    235\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    236\u001B[0m     (inputs,)\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, torch\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m()\n\u001B[0;32m    241\u001B[0m )\n\u001B[0;32m    243\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001B[38;5;28mlen\u001B[39m(tensors))\n\u001B[1;32m--> 244\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m \u001B[43m_make_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_grads_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:127\u001B[0m, in \u001B[0;36m_make_grads\u001B[1;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[0;32m    121\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad can be implicitly created only for real scalar outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mout\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    124\u001B[0m         )\n\u001B[0;32m    125\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[0;32m    126\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 127\u001B[0m         \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m     )\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    130\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, CFG.epochs + start_epoch):\n",
    "    global_step = len(train_loader) * epoch\n",
    "\n",
    "    #TRAIN\n",
    "    train_loss, preds_train, gt_train = train_func(model, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "    train_grad_flow_plot = training_supervision.get_plot_grad_flow(model)\n",
    "\n",
    "    f1_train = f1_score(gt_train, preds_train, average=\"micro\")\n",
    "    writer.add_scalar('Accuracy/Train', f1_train, global_step)\n",
    "    print(f\"[TRAIN] Training F1-Score {f1_train}\")\n",
    "\n",
    "    #Model Gradients\n",
    "    names, gradmean = training_supervision.get_model_grads(model)\n",
    "    _limits = np.array([float(i) for i in range(len(gradmean))])\n",
    "    _num = len(gradmean)\n",
    "    writer.add_histogram_raw(tag=\"ModelGrads/MeanGradientFlow\", min=0.0, max=0.5, num=_num,\n",
    "                             sum=gradmean.sum(), sum_squares=np.power(gradmean, 2).sum(), bucket_limits=_limits,\n",
    "                             bucket_counts=gradmean, global_step=global_step)\n",
    "\n",
    "    #VAL\n",
    "    val_loss, preds_val, gt_val = eval_func(model, criterion, val_loader, epoch)\n",
    "\n",
    "    f1_val_micro = f1_score(gt_val, preds_val, average=\"micro\")\n",
    "    f1_val_macro = f1_score(gt_val, preds_val, average=\"macro\")\n",
    "    writer.add_scalar('Accuracy/Validation/F1-Micro', f1_val_micro, global_step)\n",
    "    writer.add_scalar('Accuracy/Validation/F1-Macro', f1_val_macro, global_step)\n",
    "    print(f\"[EVAL] Validation F1-Score Micro {f1_val_micro}\")\n",
    "    print(f\"[EVAL] Validation F1-Score Macro {f1_val_macro}\")\n",
    "\n",
    "    #Conf Mat\n",
    "    cm = sklearn.metrics.confusion_matrix(gt_val, preds_val)\n",
    "    cm_plot = training_supervision.plot_confusion_matrix(cm, CFG.classes)\n",
    "    writer.add_figure(\"Confusion Matrix/Validation\", cm_plot, global_step)\n",
    "\n",
    "    #Model Weights\n",
    "    names, params = training_supervision.get_model_weights(model)\n",
    "    for n, p in zip(names, params):\n",
    "        writer.add_histogram(f\"ModelWeights/{n}\", p, global_step)\n",
    "\n",
    "    print(\"[EVAL] Classification Report\")\n",
    "    print(classification_report(gt_val, preds_val, target_names=CFG.classes, digits=3))\n",
    "\n",
    "    scheduler.step(val_loss)  #for reduce lr on plateau\n",
    "\n",
    "    PATH = f\"fine_tuned_models_occluded_hand_detection/{CFG.experiment_name}/f1{f1_val_micro}_valloss{val_loss}_epoch{epoch}.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'f1_micro_val-score': f1_val_micro,\n",
    "    }, PATH)\n",
    "    print(\"[INFO] MODEL SAVED\")\n",
    "    \n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:13.810714900Z",
     "start_time": "2024-01-10T00:36:11.982020900Z"
    }
   },
   "id": "33de09290ba20fd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
