{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:40:07.994780700Z",
     "start_time": "2024-01-10T00:40:07.969767100Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from model import aagcn, loss, SAM\n",
    "from utils import adj_mat, training_supervision\n",
    "from data.handpose_dataset import HandPoseDatasetNumpy, df_to_numpy\n",
    "from data.get_data_from_csv import get_train_data, get_val_data\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "from config_fine_tuning_occluded_hand_detection import CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e18a904b2db6ab6a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": "Model(\n  (data_bn): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (l1): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (down): Sequential(\n        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l2): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l3): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l4): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(64, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=64, out_features=32, bias=True)\n      (fc2c): Linear(in_features=32, out_features=64, bias=True)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l5): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(128, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(128, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=128, out_features=64, bias=True)\n      (fc2c): Linear(in_features=64, out_features=128, bias=True)\n      (down): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(9, 1), stride=(2, 1), padding=(4, 0))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n    (residual): unit_tcn(\n      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 1))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (l6): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(128, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(128, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=128, out_features=64, bias=True)\n      (fc2c): Linear(in_features=64, out_features=128, bias=True)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (l7): TCN_GCN_unit(\n    (gcn1): unit_gcn(\n      (conv_d): ModuleList(\n        (0-2): 3 x Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_a): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_b): ModuleList(\n        (0-2): 3 x Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (conv_ta): Conv1d(128, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n      (conv_sa): Conv1d(128, 1, kernel_size=(21,), stride=(1,), padding=(10,))\n      (fc1c): Linear(in_features=128, out_features=64, bias=True)\n      (fc2c): Linear(in_features=64, out_features=128, bias=True)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (soft): Softmax(dim=-2)\n      (tan): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU(inplace=True)\n    )\n    (tcn1): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(9, 1), stride=(2, 1), padding=(4, 0))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (relu): ReLU(inplace=True)\n    (residual): unit_tcn(\n      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 1))\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (fc): Linear(in_features=128, out_features=6, bias=True)\n  (drop_out): Dropout(p=0.5, inplace=False)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'trained_models/7_AAGCN_Focal_seqlen32_release_SAM_joints1_joints2_oridist/f10.8142688679245284_valloss310.2437744140625_epoch13.pth'\n",
    "\n",
    "graph = aagcn.Graph(adj_mat.num_node, adj_mat.self_link, adj_mat.inward, adj_mat.outward, adj_mat.neighbor)\n",
    "\n",
    "model = aagcn.Model(num_class=CFG.num_classes, num_point=21, num_person=1, graph=graph, drop_out=0.5,\n",
    "                    in_channels=CFG.num_feats)\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:00.064844100Z",
     "start_time": "2024-01-10T00:35:59.685588400Z"
    }
   },
   "id": "2169ad9f860d1525"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modify model -> 3 classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11b0dce12eb5a46"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.3934, -1.2816, -0.2832,  0.0083, -1.4112, -0.6198,  0.2116, -0.8508,\n          0.0153,  1.6623,  0.2825,  0.4693,  0.9603,  0.1855, -1.1737, -0.3825,\n         -0.8257,  1.4569,  1.7515,  0.2982, -1.1137, -1.3337,  0.3068, -0.4123,\n         -0.4261,  0.9741,  0.7653, -0.2347,  0.3605,  0.1354,  0.0198, -1.8644,\n          0.2086, -1.2205, -0.6561,  1.7379, -0.7430,  0.5457,  0.3010, -0.4721,\n         -1.7002,  0.9229, -0.9523,  0.7504,  0.6512,  0.4300,  1.7054,  0.5913,\n         -0.1570, -0.1880, -0.2956, -0.1273, -0.7981, -1.1487, -1.0729, -0.0380,\n          0.8234,  0.7685,  0.8407,  0.7783, -0.3994, -0.1769, -0.0188,  1.1419,\n         -1.1534,  0.2771,  0.0415, -0.5472, -0.1558, -0.2133, -1.9954,  0.8369,\n         -0.9280,  0.0053, -0.1966, -0.2587,  0.7253,  0.3017, -0.4302,  0.1958,\n          0.6542, -0.3581,  1.3611,  0.6461,  0.1558, -1.3570,  0.6970,  0.2455,\n         -1.1545,  0.5867, -0.1225, -0.8771, -0.2988,  0.3984,  0.0684, -0.4869,\n          0.6446, -0.4028,  1.2141, -0.8207, -0.0395, -0.0029, -1.0322, -1.0790,\n         -0.7964, -0.0457,  0.0447,  1.5203, -1.9005,  0.2292,  0.1803,  1.4645,\n         -0.0029,  2.3993, -0.3698,  0.5072, -1.0834, -1.7166, -1.2374, -0.0703,\n          1.5783,  1.0071,  0.7174,  0.6115,  0.5336,  0.6710,  0.7048, -0.4443],\n        [ 0.3790, -0.4452,  0.7694, -0.0592,  0.9254, -1.5119, -0.3370, -0.8903,\n          1.5826,  1.7776,  0.3028,  0.2629,  0.1979, -0.2565, -2.2546,  0.0198,\n          1.7431,  0.4315,  1.1271, -1.5718,  0.2683, -0.6926, -0.4707, -1.1293,\n          0.0920,  0.1511,  2.1698, -0.3284, -1.5606, -0.7974,  0.1720, -0.0257,\n          0.8958, -0.6654,  0.2954,  0.2382,  0.1605,  1.0645, -0.4511, -0.3034,\n          0.4112,  0.1762,  1.3368, -0.6299, -0.3504,  0.7731,  0.0570,  0.4472,\n          0.1346, -2.0302, -0.4605,  0.9913,  0.9758, -0.1882,  0.7907,  0.0710,\n         -0.3655,  0.4735,  0.5844,  0.2866, -0.6711,  0.8710,  0.8504,  0.0042,\n          0.3164,  1.1662, -0.6367,  0.6752, -0.0109,  0.6680,  1.2649,  0.2834,\n         -0.1465,  1.7174,  0.9341, -1.0303,  0.6253,  0.4240,  0.4832,  0.3784,\n          1.1858, -0.9780, -0.5897,  0.3892, -0.5136, -0.1959,  0.8003,  1.0051,\n          0.9184, -0.7279,  0.4897,  1.1390,  0.4322, -0.0047, -1.7239,  1.2200,\n         -0.6971,  0.0457,  0.4057,  1.4939, -0.0532,  0.6773,  0.0442,  0.3350,\n         -1.6581, -0.0673, -1.1917,  0.9159,  0.1747, -0.1603, -1.4883, -0.1610,\n          0.2343, -0.0512,  0.0613,  1.0229,  0.8188, -0.1249, -0.4110, -1.3917,\n          1.0424,  0.3320, -1.5974,  2.0843,  0.1520, -1.2780, -0.3585,  0.1120],\n        [-1.4781, -0.4247, -0.3310, -0.5279, -1.0693,  0.1617, -0.7363,  1.6434,\n         -0.2859,  0.1259, -0.1040,  0.6482, -0.8641,  0.0265,  0.0950, -2.2683,\n          1.9746, -0.5154, -0.9230,  0.0919,  1.9824,  0.1467, -0.3500,  0.0037,\n         -0.1254,  0.4995,  0.1535,  1.5276, -0.7169,  1.2993, -0.0971, -0.3214,\n          1.5557, -0.7519,  0.1309,  0.4166,  1.5959, -1.2479, -1.1650, -0.6531,\n          0.4848, -0.4010,  1.1524,  0.4170,  0.3655,  0.6519,  1.0789, -0.1349,\n         -0.2545, -0.5268,  0.2636, -0.6682, -0.1559,  0.1645,  0.3971, -0.7806,\n          0.0087, -0.4999,  1.8035, -1.7857, -1.2532, -0.7158, -0.0591, -0.0688,\n          0.1110, -0.9506,  0.2172,  1.4249, -0.4999, -0.4720, -1.2759,  0.9883,\n          0.8800,  1.1634, -0.8801,  0.8325, -0.0085,  1.2233, -0.0637, -0.0400,\n          0.8496,  1.9843,  0.2028, -0.0031, -0.3172,  0.9127,  0.0712, -0.2717,\n          0.3651, -0.2794, -0.0643, -0.3156, -0.8749, -0.2617,  0.8624,  0.3323,\n          0.1068, -0.3101,  1.4907, -1.6857,  0.0726, -0.0826, -0.7576, -1.5364,\n          0.9496, -0.5333, -0.4417, -0.6981, -0.4220,  0.5702, -0.4529, -0.4211,\n          1.4175,  0.3127,  0.3267,  0.1113, -1.3457, -0.5592,  0.1209,  0.2168,\n         -0.0933, -0.2095,  0.2521,  0.2082, -0.3946, -0.9749,  0.2011, -0.6415]],\n       device='cuda:0', requires_grad=True)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_fine_tuning = len(CFG.classes_fine_tuning)\n",
    "\n",
    "# change last layer\n",
    "model.fc = nn.Linear(128, num_classes_fine_tuning).to(device)\n",
    "\n",
    "# init the new layer\n",
    "nn.init.normal_(model.fc.weight, 0, math.sqrt(2. / num_classes_fine_tuning))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:00.170180300Z",
     "start_time": "2024-01-10T00:36:00.058839800Z"
    }
   },
   "id": "dc1758e49dcac320"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9eac5679f84793c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       WRIST  THUMB_CMC  THUMB_MCP   THUMB_IP  THUMB_TIP INDEX_FINGER_MCP  \\\n0  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n1  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n2  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n3  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n4  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)        (0, 0, 0)   \n\n  INDEX_FINGER_PIP INDEX_FINGER_DIP INDEX_FINGER_TIP MIDDLE_FINGER_MCP  ...  \\\n0        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n1        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n2        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n3        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n4        (0, 0, 0)        (0, 0, 0)        (0, 0, 0)         (0, 0, 0)  ...   \n\n  MIDDLE_FINGER_TIP RING_FINGER_MCP RING_FINGER_PIP RING_FINGER_DIP  \\\n0         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n1         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n2         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n3         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n4         (0, 0, 0)       (0, 0, 0)       (0, 0, 0)       (0, 0, 0)   \n\n  RING_FINGER_TIP  PINKY_MCP  PINKY_PIP  PINKY_DIP  PINKY_TIP     LABEL  \n0       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n1       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n2       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n3       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n4       (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  (0, 0, 0)  Negative  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WRIST</th>\n      <th>THUMB_CMC</th>\n      <th>THUMB_MCP</th>\n      <th>THUMB_IP</th>\n      <th>THUMB_TIP</th>\n      <th>INDEX_FINGER_MCP</th>\n      <th>INDEX_FINGER_PIP</th>\n      <th>INDEX_FINGER_DIP</th>\n      <th>INDEX_FINGER_TIP</th>\n      <th>MIDDLE_FINGER_MCP</th>\n      <th>...</th>\n      <th>MIDDLE_FINGER_TIP</th>\n      <th>RING_FINGER_MCP</th>\n      <th>RING_FINGER_PIP</th>\n      <th>RING_FINGER_DIP</th>\n      <th>RING_FINGER_TIP</th>\n      <th>PINKY_MCP</th>\n      <th>PINKY_PIP</th>\n      <th>PINKY_DIP</th>\n      <th>PINKY_TIP</th>\n      <th>LABEL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>...</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>(0, 0, 0)</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = get_train_data()  # Todo: replace with our own data\n",
    "df_train = df_train.replace(\"Postion\", \"Position\")\n",
    "df_val = get_val_data()  # Todo: replace with our own data\n",
    "\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:02.114326300Z",
     "start_time": "2024-01-10T00:36:00.167736600Z"
    }
   },
   "id": "49df6f288d86c4ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finetuning first try: remove all other classes except our 3 from the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e22c6215d8a5efd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27184 entries, 0 to 2021\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   WRIST              27184 non-null  object\n",
      " 1   THUMB_CMC          27184 non-null  object\n",
      " 2   THUMB_MCP          27184 non-null  object\n",
      " 3   THUMB_IP           27184 non-null  object\n",
      " 4   THUMB_TIP          27184 non-null  object\n",
      " 5   INDEX_FINGER_MCP   27184 non-null  object\n",
      " 6   INDEX_FINGER_PIP   27184 non-null  object\n",
      " 7   INDEX_FINGER_DIP   27184 non-null  object\n",
      " 8   INDEX_FINGER_TIP   27184 non-null  object\n",
      " 9   MIDDLE_FINGER_MCP  27184 non-null  object\n",
      " 10  MIDDLE_FINGER_PIP  27184 non-null  object\n",
      " 11  MIDDLE_FINGER_DIP  27184 non-null  object\n",
      " 12  MIDDLE_FINGER_TIP  27184 non-null  object\n",
      " 13  RING_FINGER_MCP    27184 non-null  object\n",
      " 14  RING_FINGER_PIP    27184 non-null  object\n",
      " 15  RING_FINGER_DIP    27184 non-null  object\n",
      " 16  RING_FINGER_TIP    27184 non-null  object\n",
      " 17  PINKY_MCP          27184 non-null  object\n",
      " 18  PINKY_PIP          27184 non-null  object\n",
      " 19  PINKY_DIP          27184 non-null  object\n",
      " 20  PINKY_TIP          27184 non-null  object\n",
      " 21  LABEL              27184 non-null  object\n",
      "dtypes: object(22)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train[df_train[\"LABEL\"].isin(CFG.classes_fine_tuning)]\n",
    "df_val = df_val[df_val[\"LABEL\"].isin(CFG.classes_fine_tuning)]\n",
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:02.271545Z",
     "start_time": "2024-01-10T00:36:02.115329100Z"
    }
   },
   "id": "8dc0787fc2d358cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare train and validation data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29aab5179473bf86"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TRAIN DATA DISTRIBUTION\n",
      "LABEL\n",
      "Grasp       19445\n",
      "Negative     5011\n",
      "Release      2728\n",
      "Name: count, dtype: int64\n",
      "[INFO] VALIDATION DATA DISTRIBUTION\n",
      "LABEL\n",
      "Grasp       3679\n",
      "Negative    1117\n",
      "Release      380\n",
      "Name: count, dtype: int64\n",
      "[INFO] TRAINING ON 27184 DATAPOINTS\n",
      "[INFO] VALIDATION ON 5176 DATAPOINTS\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] TRAIN DATA DISTRIBUTION\")\n",
    "print(df_train[\"LABEL\"].value_counts())\n",
    "print(\"[INFO] VALIDATION DATA DISTRIBUTION\")\n",
    "print(df_val[\"LABEL\"].value_counts())\n",
    "\n",
    "train_numpy = df_to_numpy(df_train)\n",
    "val_numpy = df_to_numpy(df_val)\n",
    "\n",
    "train_set = HandPoseDatasetNumpy(train_numpy)\n",
    "val_set = HandPoseDatasetNumpy(val_numpy)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=CFG.batch_size, drop_last=True, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=CFG.batch_size, drop_last=True, pin_memory=True)\n",
    "\n",
    "print(f\"[INFO] TRAINING ON {len(train_set)} DATAPOINTS\")\n",
    "print(f\"[INFO] VALIDATION ON {len(val_set)} DATAPOINTS\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:11.938905400Z",
     "start_time": "2024-01-10T00:36:02.178469Z"
    }
   },
   "id": "b415ca84109554c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fine tuning config and preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9db523fbb4200c5d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "optimizer_base = torch.optim.Adam\n",
    "optimizer = SAM.SAM(model.parameters(), optimizer_base, lr=CFG.lr, rho=0.5, adaptive=True)\n",
    "criterion = loss.FocalLoss()\n",
    "\n",
    "writer = SummaryWriter(f'fine_tuned_models_occluded_hand_detection/runs/{CFG.experiment_name}')\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=CFG.min_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:11.957911900Z",
     "start_time": "2024-01-10T00:36:11.941906200Z"
    }
   },
   "id": "ad310ad7e2983f47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_func(model, data_loader, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    iters = len(data_loader)\n",
    "    global_step = epoch * len(data_loader)\n",
    "    preds = []\n",
    "    groundtruth = []\n",
    "    t0 = time.time()\n",
    "    loss_total = 0\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        labels = labels.cuda().long()\n",
    "        inputs = inputs.cuda().float()\n",
    "\n",
    "        last_label = labels[:, -1, :]\n",
    "        last_label = torch.argmax(last_label, 1)\n",
    "\n",
    "        model.zero_grad()\n",
    "        last_out = model(inputs)\n",
    "\n",
    "        # first forward-backward pass\n",
    "        loss = criterion(last_out, last_label)\n",
    "        loss.backward()\n",
    "\n",
    "        if CFG.sam:\n",
    "            optimizer.first_step(zero_grad=True)  #\n",
    "\n",
    "            # second forward-backward pass\n",
    "            criterion(model(inputs), last_label).backward()  #\n",
    "            optimizer.second_step(zero_grad=True)  #\n",
    "        else:\n",
    "            optimizer.step()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        preds.append(last_out.cpu().detach().numpy())\n",
    "        groundtruth.append(last_label.cpu().detach().numpy())\n",
    "\n",
    "        loss_total += loss\n",
    "        global_step += 1\n",
    "        writer.add_scalar('Loss/Train', loss, global_step)\n",
    "        writer.add_scalar('LR', current_lr, global_step)\n",
    "\n",
    "        if i % CFG.print_freq == 1 or i == iters - 1:\n",
    "            t1 = time.time()\n",
    "            print(\n",
    "                f\"[TRAIN] Epoch: {epoch}/{CFG.epochs} | Iteration: {i}/{iters} | Loss: {loss_total / i} | LR: {current_lr} | ETA: {((t1 - t0) / i * iters) - (t1 - t0)}s\")\n",
    "\n",
    "    return loss_total, np.argmax(preds, axis=2).flatten(), np.array(groundtruth).flatten()\n",
    "\n",
    "\n",
    "def eval_func(model, criterion, data_loader, epoch):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    groundtruth = []\n",
    "    t0 = time.time()\n",
    "    loss_total = 0\n",
    "    global_step = len(train_loader) * epoch\n",
    "    iters = len(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            labels = labels.cuda().long()\n",
    "            inputs = inputs.cuda().float()\n",
    "\n",
    "            last_label = labels[:, -1, :]\n",
    "            last_label = torch.argmax(last_label, 1)\n",
    "\n",
    "            last_out = model(inputs)\n",
    "            loss = criterion(last_out, last_label)\n",
    "\n",
    "            preds.append(last_out.cpu().detach().numpy())\n",
    "            groundtruth.append(last_label.cpu().detach().numpy())\n",
    "            loss_total += loss\n",
    "\n",
    "            if i % CFG.print_freq == 1 or i == iters - 1:\n",
    "                t1 = time.time()\n",
    "                print(\n",
    "                    f\"[EVAL] Epoch: {epoch}/{CFG.epochs} | Iteration: {i}/{iters} | Val-Loss: {loss_total / i} | ETA: {((t1 - t0) / i * iters) - (t1 - t0)}s\")\n",
    "\n",
    "    writer.add_scalar('Loss/Validation', loss_total / i, global_step)\n",
    "    return loss_total, np.argmax(preds, axis=2).flatten(), np.array(groundtruth).flatten()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f58e55abe0c3428f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Early stopping to stop training automatically when model doesn't improve anymore"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccfc21c34681e185"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, delta=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:11.979018100Z",
     "start_time": "2024-01-10T00:36:11.958912200Z"
    }
   },
   "id": "b0e3fc32c91296cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start Fine tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe8f85ca1658b36b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m global_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader) \u001B[38;5;241m*\u001B[39m epoch\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#TRAIN\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m train_loss, preds_train, gt_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m train_grad_flow_plot \u001B[38;5;241m=\u001B[39m training_supervision\u001B[38;5;241m.\u001B[39mget_plot_grad_flow(model)\n\u001B[0;32m     10\u001B[0m f1_train \u001B[38;5;241m=\u001B[39m f1_score(gt_train, preds_train, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmicro\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\train.py:76\u001B[0m, in \u001B[0;36mtrain_func\u001B[1;34m(model, data_loader, criterion, optimizer, scheduler, epoch)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# first forward-backward pass\u001B[39;00m\n\u001B[0;32m     75\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(last_out, last_label)\n\u001B[1;32m---> 76\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m CFG\u001B[38;5;241m.\u001B[39msam:\n\u001B[0;32m     79\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mfirst_step(zero_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m#\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\venv\\lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:244\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    235\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    236\u001B[0m     (inputs,)\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, torch\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m()\n\u001B[0;32m    241\u001B[0m )\n\u001B[0;32m    243\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001B[38;5;28mlen\u001B[39m(tensors))\n\u001B[1;32m--> 244\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m \u001B[43m_make_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_grads_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n",
      "File \u001B[1;32m~\\PycharmProjects\\Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:127\u001B[0m, in \u001B[0;36m_make_grads\u001B[1;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[0;32m    121\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad can be implicitly created only for real scalar outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mout\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    124\u001B[0m         )\n\u001B[0;32m    125\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[0;32m    126\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 127\u001B[0m         \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m     )\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    130\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, CFG.epochs + start_epoch):\n",
    "    global_step = len(train_loader) * epoch\n",
    "\n",
    "    #TRAIN\n",
    "    train_loss, preds_train, gt_train = train_func(model, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "    train_grad_flow_plot = training_supervision.get_plot_grad_flow(model)\n",
    "\n",
    "    f1_train = f1_score(gt_train, preds_train, average=\"micro\")\n",
    "    writer.add_scalar('Accuracy/Train', f1_train, global_step)\n",
    "    print(f\"[TRAIN] Training F1-Score {f1_train}\")\n",
    "\n",
    "    #Model Gradients\n",
    "    names, gradmean = training_supervision.get_model_grads(model)\n",
    "    _limits = np.array([float(i) for i in range(len(gradmean))])\n",
    "    _num = len(gradmean)\n",
    "    writer.add_histogram_raw(tag=\"ModelGrads/MeanGradientFlow\", min=0.0, max=0.5, num=_num,\n",
    "                             sum=gradmean.sum(), sum_squares=np.power(gradmean, 2).sum(), bucket_limits=_limits,\n",
    "                             bucket_counts=gradmean, global_step=global_step)\n",
    "\n",
    "    #VAL\n",
    "    val_loss, preds_val, gt_val = eval_func(model, criterion, val_loader, epoch)\n",
    "\n",
    "    f1_val_micro = f1_score(gt_val, preds_val, average=\"micro\")\n",
    "    f1_val_macro = f1_score(gt_val, preds_val, average=\"macro\")\n",
    "    writer.add_scalar('Accuracy/Validation/F1-Micro', f1_val_micro, global_step)\n",
    "    writer.add_scalar('Accuracy/Validation/F1-Macro', f1_val_macro, global_step)\n",
    "    print(f\"[EVAL] Validation F1-Score Micro {f1_val_micro}\")\n",
    "    print(f\"[EVAL] Validation F1-Score Macro {f1_val_macro}\")\n",
    "\n",
    "    #Conf Mat\n",
    "    cm = sklearn.metrics.confusion_matrix(gt_val, preds_val)\n",
    "    cm_plot = training_supervision.plot_confusion_matrix(cm, CFG.classes)\n",
    "    writer.add_figure(\"Confusion Matrix/Validation\", cm_plot, global_step)\n",
    "\n",
    "    #Model Weights\n",
    "    names, params = training_supervision.get_model_weights(model)\n",
    "    for n, p in zip(names, params):\n",
    "        writer.add_histogram(f\"ModelWeights/{n}\", p, global_step)\n",
    "\n",
    "    print(\"[EVAL] Classification Report\")\n",
    "    print(classification_report(gt_val, preds_val, target_names=CFG.classes, digits=3))\n",
    "\n",
    "    scheduler.step(val_loss)  #for reduce lr on plateau\n",
    "\n",
    "    PATH = f\"fine_tuned_models_occluded_hand_detection/{CFG.experiment_name}/f1{f1_val_micro}_valloss{val_loss}_epoch{epoch}.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'f1_micro_val-score': f1_val_micro,\n",
    "    }, PATH)\n",
    "    print(\"[INFO] MODEL SAVED\")\n",
    "    \n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:36:13.810714900Z",
     "start_time": "2024-01-10T00:36:11.982020900Z"
    }
   },
   "id": "33de09290ba20fd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
